{
  "datasource": {
    "key": "concepts",
    "name": "Detailed explination of the concepts behind the DADI platform",
    "requestParams": [{
      "param": "concept", "field": "handle"
    }],
    "source": {
      "type": "static",
      "data": [
        {
          "handle": "data-driven-experiences",
          "title": "Data Driven Experiences",
          "overview": "The ability to process and understand user and environmental data in real time in order to provide a customized experience for the individual across multiple touch-points.",
          "body": "## Overview\n\nDADI is unique in its approach to data: the entire platform is built to facilitate Data Driven Experiences.\n\nA data driven experience is any interaction with a product (website, app or any other digital channel) that is unique to an individual as a result of decisions made on the back of person-level data.\n\nDADI puts the concept of the individual at the heart of the platform, creating real-time, person-level taxonomies of interests, and providing multiple actionable data points to enable the construction of individual-specific experiences.\n\n## Examples of data driven experiences\n\nA data driven experience can range from the simple to the highly complex, and can be constructed in both the anonymous and known user spaces.\n\nOne basic example is the delivery of movie reviews that respect regional embargos based on the user's location at the point of page request. Another basic example is the selection of new movie reviews that pays respect to reviews that user has already read, ensuring that they receive new content on each visit.\n\nA more complex example would be the selection of articles for the individual based on a person-level taxonomy of interest and weighted through the use of machine learning and proximity to other users.\n\nAnother complex example is the recommendation of a new car for a user at the point that they first interact with a car reviews website, selected through the use of a proximity mapping and enhanced with machine learning as the user engages with the process. This data could then be fed through to an on-hand call centre to enable an informed and relevant concierge service to lead the user to point of delivery of their new car.\n\n## How does this work?\n\nAt the heart of the DADI platform is the concept of the anonymous UUID: a persistent anonymized user record that is available cross product. This is provided by DADI Identity.\n\nUsed in conjunction with DADI Track, Identity enables the monitoring of every action taken within a product, and can hand this data over to the known space at the point of user sign up/in.\n\nBy applying DADI Match to content, it is possible to automatically categorize content against our common taxonomical-framework (the most comprehensive framework available). Match is a machine learning layer that is capable of understanding the meaning of actions. When matched to content and tied to a UUID, this enables person-level taxonomies to be created and evolved in real time.\n\nAll of this data is then piped into the front end generator for a product ahead of data source execution, allowing the manipulation of content based on what is known about an individual.\n\nAs the platform learns, it gains in accuracy, providing an ever greater understanding of the individual.\n\nWhen used in conjunction with a Moment Map - our communications and engagement strategy - DADI enables the creation of meaningful relationships, acting to build loyalty, increase engagement and elevate conversion."
        },
        {
          "handle": "api-first-and-cope",
          "title": "API First & COPE",
          "overview": "API-first development is the idea that whenever you are developing a piece of shared functionality for your organization it should be exposed as a RESTful HTTP(S) API to all of your other developers.",
          "body": "## Overview\n\nTraditional product design is channel and device centric. But users inhabit a multi-channel, multi-device world.\n\nChannel and/or device centric product design results in duplicated effort and wasted engineering work. API-first development is focused on removing this technical debt through the separation of the data backend and the data consuming front end.\n\nAPI-first development is the idea that whenever you are developing a piece of shared functionality for your organization it should be exposed as a RESTful HTTP(S) API to all of your other developers. Rather than creating a library or module that needs to be added to all code bases requiring the functionality, developers can consume all the necessary functionality through the API. Having developers consume all functionality through an API enforces separation of concerns and hides internal complexity.\n\nCOPE stands for Create Once, Publish Everywhere. It is about reducing editorial overhead by freeing content for use in multiple different contexts. Simply put, COPE separates data from design, making your content reusable and future-proof for new devices or platforms.\n\nTaking an API-first development approach enables COPE and brings several additional benefits:\n\n1. [Separation of concerns](#1-separation-of-concerns)\n2. [Scalability](#2-scalability)\n3. [Reduction of language barriers](#3-reduction-of-language-barriers)\n4. [Developer liberation and specialization](#4-developer-liberation-and-specialization)\n5. [Openness and future consumer availability](#5-openness-and-future-consumer-availability)\n6. [Modularity](#6-modularity)\n\n## 1. Separation of concerns\n\nAPI-first development is the formal separation of the front end from the back end.\n\nSimilar to the Model View Controller paradigm, by decoupling data from logic from presentation, it forces a better code architecture, which in the long term decreases your technical debt. API-first development makes it easy to push data to multiple views, regardless of size or functionality.\n\n## 2. Scalability\n\nCompletely separating your front end and back end codebases helps to simplify future scalability by enabling you to scale platform components independently of each other. It allows for the client and server to sit behind their own load balancers and in their own infrastructure, giving you the ability to scale on a micro-level which brings flexibility (for example your data could be stored centrally while your client is hosted in multiple geographical locations) and cost savings.\n\n## 3. Reduction of language barriers\n\nYour API should be a reflection of your business logic. Separating it out gives you the capability of expanding into different channels and in support of different devices while utilising the same backend.\n\nYour API acts as a universal language, which any of your clients can interact with. Even as you expand, every team will be speaking and understanding the same language. The expectations are always the same: same successes, same errors. Better yet, everybody knows JSON and almost everyone is up to speed with REST, so the API is globally understood.\n\n## 4. Developer liberation and specialization\n\nAPI-first development liberates developers. The only thing application developers need to know is the request/response sequences of each API endpoint and any potential error codes. The same goes for mobile developers, and any other type of developer for that matter.\n\nIndustries move forward when knowledge can be ‘black boxed’. Imagine if, to build a web application, you had to know how to build a microchip from scratch. Thanks to specialization and division of labor all you need to focus on is the code. This is the advantage of API-first development.\n\nThe approach frees up the front end development team to focus on a few specific ways to interact with the data, and the back end team can focus on providing it in a RESTful manner.\n\n## 5. Openness and future consumer availability\n\nAPI-first makes opening your API for public consumption simple. And as a client of our own API, as you add more functionality you will be in a position to offer it to consumers without any additional overhead.\n\n## 6. Modularity\n\nWhy limit yourself to just one source of data? With modern web practices you can easily combine multiple APIs to make a powerful product quickly. And if your needs change, so can the your platform, by simply adding or removing an API."
        },
        {
          "handle": "microservices",
          "title": "Microservices",
          "overview": "Microservices describes a method of architecting complex applications as a series of small, independent processes that communicate with each other using language-agnostic APIs.",
          "body": "## Overview\n\nThe term \"Microservice Architecture\" describes a particular way of designing software applications as suites of independently deployable services. While there is no precise definition of this architectural style, there are certain common characteristics, including organization around business capability, automated deployment, intelligence in the endpoints, and decentralized control of languages and data.\n\nWe see microservices as being a logical partner of the API-first development approach, in which complex applications are composed of small, independent processes that communicate with each other using language-agnostic APIs. These services are small, highly decoupled and focus on performing a small task.\n\n## Properties of the Microservices architecture:\n\n* The services are easy to replace\n* Services are organized around capabilities, e.g. user interface frontend, recommendation, logistics, billing, etc.\n\n## A microservices-based architecture:\n\n* Lends itself to a continuous delivery software development process\n* Is distinct from a Service-oriented architecture (SOA) in that the latter aims at integrating various (business) applications whereas several microservices belong to one application only\n\n## Products not projects\n\nMost application development efforts that we see use a project model where the aim is to deliver some piece of software which is then considered to be completed. On completion the software is handed over to a maintenance organization and the project team that built it is disbanded.\n\nMicroservice proponents tend to avoid this model, preferring instead the notion that a team should own a product over its full lifetime. A common inspiration for this is Amazon's notion of \"you build, you run it\" where a development team takes full responsibility for the software in production. This brings developers into day-to-day contact with how their software behaves in production, and increases contact with their users, as they have to take on at least some of the support burden.\n\nThe product mentality ties in with the linkage to business capabilities. Rather than looking at the software as a set of functionality to be completed, there is an ongoing relationship where the question is how can software assist its users to enhance the business capability.\n\n## How big is a microservice?\n\nAlthough \"microservice\" describes an architectural style, it's name does lead to an unfortunate focus on the literal size of a service, and arguments about what constitutes \"micro\".\n\nThe largest sizes we see follow Amazon's notion of the Two Pizza Team (i.e. the whole team can be fed by two pizzas), meaning no more than a dozen people. On the other end of the spectrum, a single developer could easily be responsible for multiple services."
        },
        {
          "handle": "machine-learning",
          "title": "Machine Learning",
          "overview": "Machine Learning is not really a machine. Rather it's a mathematical model capable of learning patterns in large data sets and then predicting similar patterns in new data.",
          "body": "## Overview\n\nDADI is unique in its approach to data: the entire platform is built to facilitate [Data Driven Experiences](/platform/concepts/data-driven-experiences/).\n\nAt the heart of this is a series of cognitive apps that provide predictive analysis to enable the creation of unique experiences targeted at the individual.\n\n## Cognitive insight with DADI Predict\n\nDADI Predict is the first of our machine learning apps. It is an API that simplifies audience-based predictions by using specific machine learning techniques.\n\nVery basically, events go into DADI Predict and predictions about future events come out.\n\n## A working example\n\nDADI Predict uses the concepts of events - familiar to anyone that has used GA - to allow for the simple collection of data points to model against.\n\nAn event is a grouping of four types:\n\n- Person\n- Action\n- Object\n- Weighting\n\nFor example: user A (the person) may add a Porsche 911 (the object) to their wishlist (the action).\n\nPredict uses our identity tools - specifically the guarantee of an individual and an issued UUID - to populate the identifier for the person in the event.\n\nThe actions and the objects are based on the predictions that we want to make within a product.\n\nGoing back to the example:\n\n1. User A adds a Porsche 911 to their wishlist\n2. User B adds a Porsche 911 and a Mercedes S-Class to their wishlist\n\nThis enables us to predict that User A is more likely to be interested in a Mercedes S-Class than in a randomly selected model.\n\nThe analytical approach being used is called collaborative filtering: the prediction of interests for a single user (filtering), calculated based on the interests of many users (collaborating).\n\nThe system works best at scale. Generally speaking, it needs at least 20x more data points than variables.\n\nAnd the more data you throw at it, [the better it gets](/latest/striving-to-be-less-wrong/)."
        }
      ]
    }
  }
}
