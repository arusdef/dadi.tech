{
  "datasource": {
    "key": "concepts",
    "name": "Detailed explination of the concepts behind the DADI platform",
    "requestParams": [
      {
        "param": "concept",
        "field": "handle"
      },
      {
        "param": "lang",
        "field": "lang"
      }
    ],
    "source": {
      "type": "static",
      "data": [
        {
          "lang": "en",
          "handle": "data-driven-experiences",
          "title": "Data Driven Experiences",
          "overview": "The ability to process and understand user and environmental data in real time in order to provide a customized experience for the individual across multiple touch-points.",
          "body": "## Overview\n\nDADI is unique in its approach to data: the entire platform is built to facilitate Data Driven Experiences.\n\nA data driven experience is any interaction with a product (website, app or any other digital channel) that is unique to an individual as a result of decisions made on the back of person-level data.\n\nDADI puts the concept of the individual at the heart of the platform, creating real-time, person-level taxonomies of interests, and providing multiple actionable data points to enable the construction of individual-specific experiences.\n\n## Examples of data driven experiences\n\nA data driven experience can range from the simple to the highly complex, and can be constructed in both the anonymous and known user spaces.\n\nOne basic example is the delivery of movie reviews that respect regional embargos based on the user's location at the point of page request. Another basic example is the selection of new movie reviews that pays respect to reviews that user has already read, ensuring that they receive new content on each visit.\n\nA more complex example would be the selection of articles for the individual based on a person-level taxonomy of interest and weighted through the use of machine learning and proximity to other users.\n\nAnother complex example is the recommendation of a new car for a user at the point that they first interact with a car reviews website, selected through the use of a proximity mapping and enhanced with machine learning as the user engages with the process. This data could then be fed through to an on-hand call centre to enable an informed and relevant concierge service to lead the user to point of delivery of their new car.\n\n## How does this work?\n\nAt the heart of the DADI platform is the concept of the anonymous UUID: a persistent anonymized user record that is available cross product. This is provided by DADI Identity.\n\nUsed in conjunction with DADI Track, Identity enables the monitoring of every action taken within a product, and can hand this data over to the known space at the point of user sign up/in.\n\nBy applying DADI Match to content, it is possible to automatically categorize content against our common taxonomical-framework (the most comprehensive framework available). Match is a machine learning layer that is capable of understanding the meaning of actions. When matched to content and tied to a UUID, this enables person-level taxonomies to be created and evolved in real time.\n\nAll of this data is then piped into the front end generator for a product ahead of data source execution, allowing the manipulation of content based on what is known about an individual.\n\nAs the platform learns, it gains in accuracy, providing an ever greater understanding of the individual.\n\nWhen used in conjunction with a Moment Map - our communications and engagement strategy - DADI enables the creation of meaningful relationships, acting to build loyalty, increase engagement and elevate conversion."
        },
        {
          "lang": "de",
          "handle": "data-driven-experiences",
          "title": "Datengestützte Erlebnisse",
          "overview": "Die Fähigkeit, Benutzer- und Umgebungsdaten in Echtzeit zu verarbeiten und zu verstehen, um eine persönliche Erfahrung des Individuums über verschiedene Berührungspunkte hinweg zu ermöglichen.",
          "body": "## Überblick\n\nDADI ist einzigartig im Umgang mit Daten: Die gesamte Plattform ist darauf ausgerichtet, datengestützte Erlebnisse zu ermöglichen.\n\nEin datengestütztes Erlebnis ist jede Interaktion mit einem Produkt (Webseite, App oder jeder andere digitale Kanal), die einzigartig für jedes Individuum ist und ein Ergebnis der früheren Entscheidungen auf Grundlage der persönlichen Daten ist.\n\nDADI macht das Konzept des Individuellen zum Herzstück seiner Plattform, erstellt in Echtzeit persönliche Taxonomien zu den Interessen und bietet so zahlreiche umsetzbare Datenpunkte, die es ermöglichen, individual-spezifische Erlebnisse zu konstruieren.\n\n## Beispiele für datengestützte Erlebnisse\n\nEin datengestütztes Erlebnis kann sich vom Einfachen bis hin zum Hochkomplexen erstrecken, und es kann sowohl im anonymen als auch im bekannten Userbereich konstruiert werden.\n\nEin grundlegendes Beispiel ist die Verfügbarkeit von Filmvorschauen, die regionale Verbote berücksichtigen, basierend auf dem Standort des Benutzers, von welchem aus er die Seite aufruft. Ein anderes grundlegendes Beispiel ist die Auswahl von Filmvorschauen, die berücksichtigt, was der Benutzer bereits gelesen hat, und somit sicherstellt, dass der Benutzer bei jedem Besuch neuen Inhalt vorfindet.\n\nEin eher komplexes Beispiel ist die Auswahl von Artikeln basierend auf einer persönlichen Taxonomy der Interessen und dessen Bewertung durch maschinelles Lernen und in der Nähe zu anderen Benutzern.\n\nEin weiteres komplexes Beispiel ist die Empfehlung eines neuen Autos für einen Benutzer zu der Zeit, zu der er sich gerade zum ersten Mal auf einer Webseite für Autobewertungen befindet, ausgewählt durch die Benutzung von Nachbarschaftsanalyse und erweitert durch maschinelles Lernen, während der Benutzer sich im Prozess befindet. Diese Daten können dann an ein vorliegendes Call Centre weitergegeben werden, um einen informierten und relevanten Concierge Service anzubieten, der den Benutzer bis zur Zustellung des neuen Autos begleitet.\n\n ## Wie funktioniert das?\n\nIm Herzen der DADI Plattform liegt das Konzept der anonymen UUID: Eine dauerhafte anonymisierte Benutzerdatei, die über verschiedene Produkte hinweg verfügbar ist. Dies wird durch DADI Identity ermöglicht. Wird es in Verbindung mit DADI Track benutzt, ermöglicht Identity die Überwachung jeglicher Aktionen, die im Produkt getätigt werden, und diese Daten können an den bekannten Ort übermittelt werden, wenn der Benutzer sich registriert/anmeldet.\n\nDie Anwendung von DADI Match auf den Inhalt ermöglicht es, Inhalt nach unserem bekannten taxonomischen Framework zu kategorisieren (das flächendeckendste Framework zur Zeit verfügbar). Match ist eine Oberfläche zu maschinellem Lernen, das in der Lage ist, die Bedeutung von Aktionen zu erkennen. Wenn es mit Inhalt kombiniert wird und an ein UUID gekoppelt wird, erlaubt es einem, persönliche Taxonomien in Echtzeit zu erstellen und herauszubilden.\n\nAll diese Daten werden dann in einen Front-End Generator für ein Produkt vor der Durchführung der Datenquelle eingespeist, was die Bearbeitung des Inhalts basierend auf allem, was über das Individuum bekannt ist, ermöglicht.\n\nWährend die Plattform lernt, wird sie akurater und bietet ein immer besseres Verständnis des Individuums.\n\nWenn es in Verbidnung mit einer Moment Map - unserer Kommunikations- und Verabredungsstrategie - kombiniert wird, ermöglicht DADI den Aufbau einer bedeutsamen Beziehung, den Aufbau von Loyalität, Erweiterung der Kundenbindung und eine verbesserte Umsetzung."
        },
        {
          "lang": "en",
          "handle": "api-first-and-cope",
          "title": "API First & COPE",
          "overview": "API-first development is the idea that whenever you are developing a piece of shared functionality for your organization it should be exposed as a RESTful HTTP(S) API to all of your other developers.",
          "body": "## Overview\n\nTraditional product design is channel and device centric. But users inhabit a multi-channel, multi-device world.\n\nChannel and/or device centric product design results in duplicated effort and wasted engineering work. API-first development is focused on removing this technical debt through the separation of the data backend and the data consuming front end.\n\nAPI-first development is the idea that whenever you are developing a piece of shared functionality for your organization it should be exposed as a RESTful HTTP(S) API to all of your other developers. Rather than creating a library or module that needs to be added to all code bases requiring the functionality, developers can consume all the necessary functionality through the API. Having developers consume all functionality through an API enforces separation of concerns and hides internal complexity.\n\nCOPE stands for Create Once, Publish Everywhere. It is about reducing editorial overhead by freeing content for use in multiple different contexts. Simply put, COPE separates data from design, making your content reusable and future-proof for new devices or platforms.\n\nTaking an API-first development approach enables COPE and brings several additional benefits:\n\n1. [Separation of concerns](#1-separation-of-concerns)\n2. [Scalability](#2-scalability)\n3. [Reduction of language barriers](#3-reduction-of-language-barriers)\n4. [Developer liberation and specialization](#4-developer-liberation-and-specialization)\n5. [Openness and future consumer availability](#5-openness-and-future-consumer-availability)\n6. [Modularity](#6-modularity)\n\n## 1. Separation of concerns\n\nAPI-first development is the formal separation of the front end from the back end.\n\nSimilar to the Model View Controller paradigm, by decoupling data from logic from presentation, it forces a better code architecture, which in the long term decreases your technical debt. API-first development makes it easy to push data to multiple views, regardless of size or functionality.\n\n## 2. Scalability\n\nCompletely separating your front end and back end codebases helps to simplify future scalability by enabling you to scale platform components independently of each other. It allows for the client and server to sit behind their own load balancers and in their own infrastructure, giving you the ability to scale on a micro-level which brings flexibility (for example your data could be stored centrally while your client is hosted in multiple geographical locations) and cost savings.\n\n## 3. Reduction of language barriers\n\nYour API should be a reflection of your business logic. Separating it out gives you the capability of expanding into different channels and in support of different devices while utilising the same backend.\n\nYour API acts as a universal language, which any of your clients can interact with. Even as you expand, every team will be speaking and understanding the same language. The expectations are always the same: same successes, same errors. Better yet, everybody knows JSON and almost everyone is up to speed with REST, so the API is globally understood.\n\n## 4. Developer liberation and specialization\n\nAPI-first development liberates developers. The only thing application developers need to know is the request/response sequences of each API endpoint and any potential error codes. The same goes for mobile developers, and any other type of developer for that matter.\n\nIndustries move forward when knowledge can be ‘black boxed’. Imagine if, to build a web application, you had to know how to build a microchip from scratch. Thanks to specialization and division of labor all you need to focus on is the code. This is the advantage of API-first development.\n\nThe approach frees up the front end development team to focus on a few specific ways to interact with the data, and the back end team can focus on providing it in a RESTful manner.\n\n## 5. Openness and future consumer availability\n\nAPI-first makes opening your API for public consumption simple. And as a client of our own API, as you add more functionality you will be in a position to offer it to consumers without any additional overhead.\n\n## 6. Modularity\n\nWhy limit yourself to just one source of data? With modern web practices you can easily combine multiple APIs to make a powerful product quickly. And if your needs change, so can the your platform, by simply adding or removing an API."
        },
        {
          "lang": "de",
          "handle": "api-first-and-cope",
          "title": "API-first und COPE",
          "overview": "Das API-first Projekt ist der Gedanke, wann auch immer ein Beitrag entwickelt wird, der geteilte Funktionalität in der Firma hat, sollte es als RESTful HTTP(S) API allen anderen Entwicklern der Firma zur Verfügung stehen.",
          "body": "## Überblick\n\nTraditionelles Produktdesign ist Kanal- und Endgerätezentriert. Aber Benutzer leben in einer Welt mit verschiedenen Kanälen und verschiedenen Endgeräten.\n\nKanal- und/oder Endgerätezentriertes Produktdesign führt zu doppeltem Arbeitsaufwand und verschwendet Arbeitskraft der Entwickler. API-first ist darauf bedacht, diese technische Bürde zu beseitigen, indem die Backend Daten und das datenintensive Frontend separiert werden\n\nAPI-first ist der Gedanke, wann auch immer ein Beitrag entwickelt wird, der geteilte Funktionalität in der Firma hat, sollte es als RESTful HTTP(S) API allen anderen Entwicklern der Firma zur Verfügung stehen.  Anstatt eine Biblothek oder Modul zu erstellen, das zu jeder Codebasis hinzugefügt werden muss, was die Voraussetzung für die Funktionalität ist, können die Entwickler auf alle nötigen Funktionen durch das API zugreifen. Wenn die Entwickler auf alle Funktionen durch das API zugreifen müssen, zwingt das zu einer Trennung der Zuständigkeiten und verschleiert interne Komplexität\n\nCOPE steht für Create Once, Publish Everywhere. Es geht darum, editoriellen Mehraufwand zu verringern, in dem der Inhalt für die Benutzung in mehreren verschiedenen Kontexten freigestellt wird. Einfach ausgedrückt trennt COPE Daten vom Design, was den Inhalt wiederverwendbar und zukunftssicher für neue Endgeräte und Plattformen macht.\n\nNutzt man die API-first Entwicklung, bringt dies COPE einige weitere Vorteile:\n\n1.Trennung der Zuständigkeiten\n2. Skalierbarkeit\n3. Verringerung von Sprachbarrieren\n4. Freiheit für Entwickler und deren Spezialisierung\n5. Offenheit und zukünftige Kundenverfügbarkeit\n6. Modularität\n\n## 1. Trennung der Zuständigkeiten\n\nAPI-first ist die formale Trennung des Frontend vom Backend.\n\nÄhnlich dem Model View Controller Paradigma, wo Daten, Logik und Präsentation entkoppelt werden, zwingt es zu einer besseren Codearchitektur, was auf lange Sicht betrachtet die technischen Hürden verringert. API-first vereinfacht es, Daten zur mehrfachen Betrachtung zu versenden, egal welcher Größe oder Funktionalität.\n\n## 2. Skalierbarkeit\n\nFrontend und Backend Codebasis komplett voneinander zu trennen hilft dabei, zukünftige Skalierbarkeit zu vereinfachen, indem es ermöglicht, Plattformkomponenten unabhängig voneinander zu skalieren. Es erlaubt sowohl dem Client als auch dem Server, hinter ihrem eigenen Load Balancer und in ihrer eigenen Infrastruktur zu sitzen, während sie die Möglichkeit haben, auf der Mikroebene zu skalieren, was Flexibilität ermöglicht (zum Beispiel können Daten zentral gespeichert werden, während der Client in verschiedenen geographischen Standorten gehosted wird) und Kosten einspart.\n\n## 3. Verringerung der Sprachbarrieren\n\nIhr API sollte ihre Geschäftsidee widerspiegeln. Ausgliedern gibt Ihnen die Möglichkeit, auf verschiedene Kanäle zu expandieren und verschiedene Endgeräte zu unterstützen, alles in Benutzung des gleichen Backends.\n\nIhr API agiert als universale Sprache, mit der all ihre Clients interagieren können. Selbst wenn sie expandieren, wird jedes Team dieselbe Sprache sprechen und verstehen. Die Erwartungen sind immer die selben: Der gleiche Erfolg, die gleichen Fehler. Besser noch, wenn jeder JSON kennt und fast jeder auf der Höhe mit REST ist, sodass API weltweit verstanden wird.\n\n## 4. Freiheit für Entwickler und deren Spezialisierung\n\nAPI-first befreit die Entwickler. Die einzige Sache, die Anwendungsentwickler wissen müssen, ist die Frage/Antwort Sequenz jedes API Endpunkts und einige potentielle Fehlercodes. Dasselbe gilt für Handyentwickler, und jede andere Art von Entwickler in diesem Bereich.\n\nDie Wirtschaft entwickelt sich weiter, wenn Wissen eine Black Box wird. Stellen sie sich vor, sie müssten wissen wie ein Mikrochip von Grundauf aufgebaut wird, um eine Internetanwendung zu erstellen. Dank der Spezialisierung und Arbeitsteilung brauchen sie sich nur auf den Code konzentrieren. Das ist der Vorteil von API-first.\n\nDieser Ansatz befreit auch das Frontend Entwicklungsteam, damit es sich auf einige spezielle Verfahren zur Interaktion mit den Daten konzentrieren kann, und das Backend Team kann sich darauf fokussieren, diese in einer RESTful Art und Weise bereitzustellen.\n\n## 5. Offenheit und zukünftige Kundenverfügbarkeit\n\nAPI-first macht die Öffnung ihres API für die Öffentlichkeit einfach. Und als Client ihres eigenen API haben sie die Möglichkeit, sobald sie mehr Funktionalität hinzufügen, ihren Kunden diese ohne zusätzlichen Mehraufwand zur Verfügung zu stellen.\n\n## 6. Modularität\n\nWarum sollten sie sich mit nur einer Datenquelle zufrieden geben? Mit modernen Internetpraktiken können Sie mehrere APIs kombinieren um schnell ein leistungsstarkes Produkt zu entwickeln. Und wenn sich ihre Wünsche ändern, kann sich auch die Plattform ändern, durch einfaches hinzufügen oder löschen eines API."
        },
        {
          "lang": "en",
          "handle": "microservices",
          "title": "Microservices",
          "overview": "Microservices describes a method of architecting complex applications as a series of small, independent processes that communicate with each other using language-agnostic APIs.",
          "body": "## Overview\n\nThe term \"Microservice Architecture\" describes a particular way of designing software applications as suites of independently deployable services. While there is no precise definition of this architectural style, there are certain common characteristics, including organization around business capability, automated deployment, intelligence in the endpoints, and decentralized control of languages and data.\n\nWe see microservices as being a logical partner of the API-first development approach, in which complex applications are composed of small, independent processes that communicate with each other using language-agnostic APIs. These services are small, highly decoupled and focus on performing a small task.\n\n## Properties of the Microservices architecture:\n\n* The services are easy to replace\n* Services are organized around capabilities, e.g. user interface frontend, recommendation, logistics, billing, etc.\n\n## A microservices-based architecture:\n\n* Lends itself to a continuous delivery software development process\n* Is distinct from a Service-oriented architecture (SOA) in that the latter aims at integrating various (business) applications whereas several microservices belong to one application only\n\n## Products not projects\n\nMost application development efforts that we see use a project model where the aim is to deliver some piece of software which is then considered to be completed. On completion the software is handed over to a maintenance organization and the project team that built it is disbanded.\n\nMicroservice proponents tend to avoid this model, preferring instead the notion that a team should own a product over its full lifetime. A common inspiration for this is Amazon's notion of \"you build, you run it\" where a development team takes full responsibility for the software in production. This brings developers into day-to-day contact with how their software behaves in production, and increases contact with their users, as they have to take on at least some of the support burden.\n\nThe product mentality ties in with the linkage to business capabilities. Rather than looking at the software as a set of functionality to be completed, there is an ongoing relationship where the question is how can software assist its users to enhance the business capability.\n\n## How big is a microservice?\n\nAlthough \"microservice\" describes an architectural style, it's name does lead to an unfortunate focus on the literal size of a service, and arguments about what constitutes \"micro\".\n\nThe largest sizes we see follow Amazon's notion of the Two Pizza Team (i.e. the whole team can be fed by two pizzas), meaning no more than a dozen people. On the other end of the spectrum, a single developer could easily be responsible for multiple services."
        },
                {
          "lang": "de",
          "handle": "microservices",
          "title": "Microservices",
          "overview": "Microservices beschreibt eine Methode, komplexe Anwendungen als eine Serie von kleinen, unabhängigen Prozessen aufzubauen, die unter Benutzung sprachunabhängier APIs miteinander kommunizieren.",
          "body": "## Überblick\n\nDer Begriff \"Microservice Architecture\" beschreibt ein bestimmtes Verfahren zum Design von Softwareanwendungen als eine Suite von unabhängigen, einsatzfähigen Services. Obwohl es keine präzise Definition dieses Architekturstils gibt, gibt es doch einige bestimmte Eigenschaften, unter anderem die Organisation um die geschäftliche Leistungsfähigkeit herum, automatische Einsatzfähigket, Intelligenz in den Endpunkten und dezentrale Kontrolle der Sprachen und Daten.\n\nWir sehen Microservices als logischen Partner des API-first Ansatzes, wo komplexe Anwendungen aus kleinen, unabhängigen Prozessen aufgebaut sind, die unter Benutzung von sprachunabhängiger APIs miteinander kommunizieren. Diese Services sind klein, hochgradig entkoppelt und konzentrieren sich darauf, kleine Aufgaben auszuführen.\n\n## Eigenschaften der Microservice Architecture:\n\n* Die Services lassen sich leicht ersetzen\n* Die Services sind nach ihrem Potential organisiert, z.B. User Schnittstellen Frontend, Empfehlung, Logistik, Abrechnung, etc.\n\n## Eine Microservice basierende Architektur:\n\n* Eignet sich für einen kontinuierlichen Softwareentwicklungsprozess\n* Ist abgesetzt von einer serviceorientierten Architektur (SOA) in dem Sinne, dass Letzteres zum Ziel hat, verschiedene (geschäftliche) Anwendungen zu integrieren, während Microservices nur zu einer Anwendung gehören.\n\n## Produkte, keine Projekte\n\nDie meisten Bestreben zur Anwendungsentwicklung, die wir kennen, nutzen ein Projektmodell, mit dem Ziel, dass ein Stück Software ausgeliefert wird, welches dann als abgeschlossen angesehen wird. Nach Abschluss wird die Software an eine Wartungsfirma ausgehändigt und das Projektteam, dass diese entwickelte, wird aufgelöst.\n\nBefürworter von Microservice tendieren dazu, dieses Modell zu vermeiden, und bevorzugen stattdessen lieber die Auffassung, dass das Team das Produkt über die Lebenszeit hinweg besitzen sollte. Eine gängige Inspiration dafür ist Amazons Auffassung von \"Ihr baut es, also betreibt ihr es auch\", bei der das Entwicklerteam die volle Verantwortung für die Software in der Produktion trägt. Dies bringt die Entwickler in täglichen Kontakt damit, wie sich ihre Software in der Produktion verhält und erhöht den Kontakt mit den Benutzern, weil sie zumindest einen Teil der Support Bürde tragen müssen.\n\nDie Produktmentalität ist verbunden mit der Geschäftstauglichkeit. Anstatt die Software nur als ein Satz von Funktionalitäten anzusehen, der abgeschlossen ist, gibt es eine dauerhafte Beziehung mit der Fragestellung, wie die Software den Benutzern helfen kann, ihre Geschäftstauglichkeit zu verbessern.\n\n## Wie groß ist ein Microservice?\n\nObwohl \"Microservice\" einen Architekturstil beschreibt, lässt der Name unglücklicherweise auf die wortwörtliche Größe des Service schließen, und auf Streitigkeiten, was \"micro\" alles beinhaltet.\n\nDie größte uns bekannte Größe folgt Amazons Auffassung der zwei Pizzen (d.h. das gesamte Team kann mit zwei Pizzen ernährt werden), was bedeutet, dass es nicht mehr als ein Dutzend Menschen sind. Auf der anderen Seite des Spektrums kann auch ein einzelner Entwickler leicht für mehrere Services verantwortlich sein."
        },
        {
          "lang": "en",
          "handle": "machine-learning",
          "title": "Machine Learning",
          "overview": "Machine Learning is not really a machine. Rather it's a mathematical model capable of learning patterns in large data sets and then predicting similar patterns in new data.",
          "body": "## Overview\n\nDADI is unique in its approach to data: the entire platform is built to facilitate [Data Driven Experiences](/platform/concepts/data-driven-experiences/).\n\nAt the heart of this is a series of cognitive apps that provide predictive analysis to enable the creation of unique experiences targeted at the individual.\n\n## Cognitive insight with DADI Predict\n\nDADI Predict is the first of our machine learning apps. It is an API that simplifies audience-based predictions by using specific machine learning techniques.\n\nVery basically, events go into DADI Predict and predictions about future events come out.\n\n## A working example\n\nDADI Predict uses the concepts of events - familiar to anyone that has used GA - to allow for the simple collection of data points to model against.\n\nAn event is a grouping of four types:\n\n- Person\n- Action\n- Object\n- Weighting\n\nFor example: user A (the person) may add a Porsche 911 (the object) to their wishlist (the action).\n\nPredict uses our identity tools - specifically the guarantee of an individual and an issued UUID - to populate the identifier for the person in the event.\n\nThe actions and the objects are based on the predictions that we want to make within a product.\n\nGoing back to the example:\n\n1. User A adds a Porsche 911 to their wishlist\n2. User B adds a Porsche 911 and a Mercedes S-Class to their wishlist\n\nThis enables us to predict that User A is more likely to be interested in a Mercedes S-Class than in a randomly selected model.\n\nThe analytical approach being used is called collaborative filtering: the prediction of interests for a single user (filtering), calculated based on the interests of many users (collaborating).\n\nThe system works best at scale. Generally speaking, it needs at least 20x more data points than variables.\n\nAnd the more data you throw at it, [the better it gets](/latest/striving-to-be-less-wrong/)."
        },
        {
          "lang": "de",
          "handle": "machine-learning",
          "title": "Maschinelles Lernen",
          "overview": "Maschinelles Lernen ist nicht wirklich eine Maschine. Es ist eher ein mathematisches Model, das in der Lage ist, Verhaltensmuster zu erlernen und daraufhin ähnliche Muster in neuen Daten vorherzusagen.",
          "body": "## Überblick\n\nDADI ist einzigartig im Umgang mit Daten: Die gesamte Plattform ist darauf ausgerichtet, datengestützte Erlebnisse zu ermöglichen.\n\nIm Kern liegen eine Reihe von kognitiven Anwendungen, die vorausschauende Analysen treffen um einzigartige Erfahrungen zielgerichtet auf ein Individuum zu ermöglichen.\n\n## Kognitiver Einblick mit DADI Predict\n\nDADI Predict ist die erste unserer Anwendungen für maschinelles Lernen. Es ist ein API, das zielgruppenbasierte Vorhersagen vereinfacht, in dem es spezielle Techniken zum maschinellen Lernen verwendet.\n\nIm Prinzip werden Ereignisse in DADI Predict gespeichert und eine Vorhersage über zukünftige Ereignisse kommt dabei heraus.\n\n## Ein arbeitsfähiges Beispiel\n\nDADI Predict nutzt die Konzepte von Ereignissen - bekannt für jeden, der ein GA benutzt - um die einfach Sammlung von Datenpunkten zum Abgleich zu ermöglichen.Ein Ereignis kann in 4 Teile gruppiert werden:\n\n* Person\n* Aktion\n* Objekt\n* Bedeutung\nnZum Beispiel: Benutzer A (die Person) fügt einen Porsche 911 (das Objekt) zu seiner Wunschliste hinzu (die Aktion).\n\nPredict nutzt unsere Tools zur Identifikation - im speziellen die Gewährleistung eines Individuums und eine ausgegebene UUID - um die Kennung der Person in dem Ereignis zu befüllen.\n\nDie Aktion und das Objekt basieren auf der Vorhersage, die wir innerhalb des Produkts machen möchten.\n\nZurück zum Beispiel\n\n1. Benutzer A fügt einen Porsche 911 zu seiner Wunschliste hinzu.\n2. Benutzer B fügt einen Porsche 911 und eine Mercedes S-Klasse zu seiner Wunschliste hinzu.\n\nDies erlaubt uns, vorherzusagen, dass Benutzer A wahrscheinlich eher an einer Mercedes S-Klasse interessiert sein wird als an einem zufällig ausgewählten Model.\n\nDer analytische Ansatz, der hier genutzt wird, nennt sich kollaboratives Filtern: Die Vorhersage von Interessen eines Einzelnen (filtern), ermittelt auf Basis der Interessen Vieler (kollaborativ).\n\nDas System arbeitet am besten in größeren Dimensionen. Allgemein gesagt benötigt es mindestens 20 mal mehr Datenpunkte als Variablen.\n\nUnd je mehr Daten es bekommt, desto besser wird es."
        }
      ]
    }
  }
}
