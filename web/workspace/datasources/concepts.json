{
  "datasource": {
    "key": "concepts",
    "name": "Detailed explination of the concepts behind the DADI platform",
    "requestParams": [
      {
        "param": "concept",
        "field": "handle"
      },
      {
        "param": "lang",
        "field": "lang"
      }
    ],
    "source": {
      "type": "static",
      "data": [
        {
          "lang": "en",
          "handle": "data-driven-experiences",
          "title": "Data Driven Experiences",
          "overview": "The ability to process and understand user and environmental data in real time in order to provide a customized experience for the individual across multiple touch-points.",
          "body": "## Overview\n\nDADI is unique in its approach to data: the entire platform is built to facilitate Data Driven Experiences.\n\nA data driven experience is any interaction with a product (website, app or any other digital channel) that is unique to an individual as a result of decisions made on the back of person-level data.\n\nDADI puts the concept of the individual at the heart of the platform, creating real-time, person-level taxonomies of interests, and providing multiple actionable data points to enable the construction of individual-specific experiences.\n\n## Examples of data driven experiences\n\nA data driven experience can range from the simple to the highly complex, and can be constructed in both the anonymous and known user spaces.\n\nOne basic example is the delivery of movie reviews that respect regional embargos based on the user's location at the point of page request. Another basic example is the selection of new movie reviews that pays respect to reviews that user has already read, ensuring that they receive new content on each visit.\n\nA more complex example would be the selection of articles for the individual based on a person-level taxonomy of interest and weighted through the use of machine learning and proximity to other users.\n\nAnother complex example is the recommendation of a new car for a user at the point that they first interact with a car reviews website, selected through the use of a proximity mapping and enhanced with machine learning as the user engages with the process. This data could then be fed through to an on-hand call centre to enable an informed and relevant concierge service to lead the user to point of delivery of their new car.\n\n## How does this work?\n\nAt the heart of the DADI platform is the concept of the anonymous UUID: a persistent anonymized user record that is available cross product. This is provided by DADI Identity.\n\nUsed in conjunction with DADI Track, Identity enables the monitoring of every action taken within a product, and can hand this data over to the known space at the point of user sign up/in.\n\nBy applying DADI Match to content, it is possible to automatically categorize content against our common taxonomical-framework (the most comprehensive framework available). Match is a machine learning layer that is capable of understanding the meaning of actions. When matched to content and tied to a UUID, this enables person-level taxonomies to be created and evolved in real time.\n\nAll of this data is then piped into the front end generator for a product ahead of data source execution, allowing the manipulation of content based on what is known about an individual.\n\nAs the platform learns, it gains in accuracy, providing an ever greater understanding of the individual.\n\nWhen used in conjunction with a Moment Map - our communications and engagement strategy - DADI enables the creation of meaningful relationships, acting to build loyalty, increase engagement and elevate conversion."
        },
        {
          "lang": "en",
          "handle": "api-first-and-cope",
          "title": "API First & COPE",
          "overview": "API-first development is the idea that whenever you are developing a piece of shared functionality for your organization it should be exposed as a RESTful HTTP(S) API to all of your other developers.",
          "body": "## Overview\n\nTraditional product design is channel and device centric. But users inhabit a multi-channel, multi-device world.\n\nChannel and/or device centric product design results in duplicated effort and wasted engineering work. API-first development is focused on removing this technical debt through the separation of the data backend and the data consuming front end.\n\nAPI-first development is the idea that whenever you are developing a piece of shared functionality for your organization it should be exposed as a RESTful HTTP(S) API to all of your other developers. Rather than creating a library or module that needs to be added to all code bases requiring the functionality, developers can consume all the necessary functionality through the API. Having developers consume all functionality through an API enforces separation of concerns and hides internal complexity.\n\nCOPE stands for Create Once, Publish Everywhere. It is about reducing editorial overhead by freeing content for use in multiple different contexts. Simply put, COPE separates data from design, making your content reusable and future-proof for new devices or platforms.\n\nTaking an API-first development approach enables COPE and brings several additional benefits:\n\n1. [Separation of concerns](#1-separation-of-concerns)\n2. [Scalability](#2-scalability)\n3. [Reduction of language barriers](#3-reduction-of-language-barriers)\n4. [Developer liberation and specialization](#4-developer-liberation-and-specialization)\n5. [Openness and future consumer availability](#5-openness-and-future-consumer-availability)\n6. [Modularity](#6-modularity)\n\n## 1. Separation of concerns\n\nAPI-first development is the formal separation of the front end from the back end.\n\nSimilar to the Model View Controller paradigm, by decoupling data from logic from presentation, it forces a better code architecture, which in the long term decreases your technical debt. API-first development makes it easy to push data to multiple views, regardless of size or functionality.\n\n## 2. Scalability\n\nCompletely separating your front end and back end codebases helps to simplify future scalability by enabling you to scale platform components independently of each other. It allows for the client and server to sit behind their own load balancers and in their own infrastructure, giving you the ability to scale on a micro-level which brings flexibility (for example your data could be stored centrally while your client is hosted in multiple geographical locations) and cost savings.\n\n## 3. Reduction of language barriers\n\nYour API should be a reflection of your business logic. Separating it out gives you the capability of expanding into different channels and in support of different devices while utilising the same backend.\n\nYour API acts as a universal language, which any of your clients can interact with. Even as you expand, every team will be speaking and understanding the same language. The expectations are always the same: same successes, same errors. Better yet, everybody knows JSON and almost everyone is up to speed with REST, so the API is globally understood.\n\n## 4. Developer liberation and specialization\n\nAPI-first development liberates developers. The only thing application developers need to know is the request/response sequences of each API endpoint and any potential error codes. The same goes for mobile developers, and any other type of developer for that matter.\n\nIndustries move forward when knowledge can be ‘black boxed’. Imagine if, to build a web application, you had to know how to build a microchip from scratch. Thanks to specialization and division of labor all you need to focus on is the code. This is the advantage of API-first development.\n\nThe approach frees up the front end development team to focus on a few specific ways to interact with the data, and the back end team can focus on providing it in a RESTful manner.\n\n## 5. Openness and future consumer availability\n\nAPI-first makes opening your API for public consumption simple. And as a client of our own API, as you add more functionality you will be in a position to offer it to consumers without any additional overhead.\n\n## 6. Modularity\n\nWhy limit yourself to just one source of data? With modern web practices you can easily combine multiple APIs to make a powerful product quickly. And if your needs change, so can the your platform, by simply adding or removing an API."
        },
        {
          "lang": "en",
          "handle": "microservices",
          "title": "Microservices",
          "overview": "Microservices describes a method of architecting complex applications as a series of small, independent processes that communicate with each other using language-agnostic APIs.",
          "body": "## Overview\n\nThe term \"Microservice Architecture\" describes a particular way of designing software applications as suites of independently deployable services. While there is no precise definition of this architectural style, there are certain common characteristics, including organization around business capability, automated deployment, intelligence in the endpoints, and decentralized control of languages and data.\n\nWe see microservices as being a logical partner of the API-first development approach, in which complex applications are composed of small, independent processes that communicate with each other using language-agnostic APIs. These services are small, highly decoupled and focus on performing a small task.\n\n## Properties of the Microservices architecture:\n\n* The services are easy to replace\n* Services are organized around capabilities, e.g. user interface frontend, recommendation, logistics, billing, etc.\n\n## A microservices-based architecture:\n\n* Lends itself to a continuous delivery software development process\n* Is distinct from a Service-oriented architecture (SOA) in that the latter aims at integrating various (business) applications whereas several microservices belong to one application only\n\n## Products not projects\n\nMost application development efforts that we see use a project model where the aim is to deliver some piece of software which is then considered to be completed. On completion the software is handed over to a maintenance organization and the project team that built it is disbanded.\n\nMicroservice proponents tend to avoid this model, preferring instead the notion that a team should own a product over its full lifetime. A common inspiration for this is Amazon's notion of \"you build, you run it\" where a development team takes full responsibility for the software in production. This brings developers into day-to-day contact with how their software behaves in production, and increases contact with their users, as they have to take on at least some of the support burden.\n\nThe product mentality ties in with the linkage to business capabilities. Rather than looking at the software as a set of functionality to be completed, there is an ongoing relationship where the question is how can software assist its users to enhance the business capability.\n\n## How big is a microservice?\n\nAlthough \"microservice\" describes an architectural style, it's name does lead to an unfortunate focus on the literal size of a service, and arguments about what constitutes \"micro\".\n\nThe largest sizes we see follow Amazon's notion of the Two Pizza Team (i.e. the whole team can be fed by two pizzas), meaning no more than a dozen people. On the other end of the spectrum, a single developer could easily be responsible for multiple services."
        },  
        {
          "lang": "en",
          "handle": "machine-learning",
          "title": "Machine Learning",
          "overview": "Machine Learning is not really a machine. Rather it's a mathematical model capable of learning patterns in large data sets and then predicting similar patterns in new data.",
          "body": "## Overview\n\nDADI is unique in its approach to data: the entire platform is built to facilitate [Data Driven Experiences](/platform/concepts/data-driven-experiences/).\n\nAt the heart of this is a series of cognitive apps that provide predictive analysis to enable the creation of unique experiences targeted at the individual.\n\n## Cognitive insight with DADI Predict\n\nDADI Predict is the first of our machine learning apps. It is an API that simplifies audience-based predictions by using specific machine learning techniques.\n\nVery basically, events go into DADI Predict and predictions about future events come out.\n\n## A working example\n\nDADI Predict uses the concepts of events - familiar to anyone that has used GA - to allow for the simple collection of data points to model against.\n\nAn event is a grouping of four types:\n\n- Person\n- Action\n- Object\n- Weighting\n\nFor example: user A (the person) may add a Porsche 911 (the object) to their wishlist (the action).\n\nPredict uses our identity tools - specifically the guarantee of an individual and an issued UUID - to populate the identifier for the person in the event.\n\nThe actions and the objects are based on the predictions that we want to make within a product.\n\nGoing back to the example:\n\n1. User A adds a Porsche 911 to their wishlist\n2. User B adds a Porsche 911 and a Mercedes S-Class to their wishlist\n\nThis enables us to predict that User A is more likely to be interested in a Mercedes S-Class than in a randomly selected model.\n\nThe analytical approach being used is called collaborative filtering: the prediction of interests for a single user (filtering), calculated based on the interests of many users (collaborating).\n\nThe system works best at scale. Generally speaking, it needs at least 20x more data points than variables.\n\nAnd the more data you throw at it, [the better it gets](/latest/striving-to-be-less-wrong/)."
        },
        {
          "lang": "de",
          "handle": "data-driven-experiences",
          "title": "Datengestützte Erlebnisse",
          "overview": "Die Fähigkeit, Benutzer- und Umgebungsdaten in Echtzeit zu verarbeiten und zu verstehen, um eine persönliche Erfahrung des Individuums über verschiedene Berührungspunkte hinweg zu ermöglichen.",
          "body": "## Überblick\n\nDADI ist einzigartig im Umgang mit Daten: Die gesamte Plattform ist darauf ausgerichtet, datengestützte Erlebnisse zu ermöglichen.\n\nEin datengestütztes Erlebnis ist jede Interaktion mit einem Produkt (Webseite, App oder jeder andere digitale Kanal), die einzigartig für jedes Individuum ist und ein Ergebnis der früheren Entscheidungen auf Grundlage der persönlichen Daten ist.\n\nDADI macht das Konzept des Individuellen zum Herzstück seiner Plattform, erstellt in Echtzeit persönliche Taxonomien zu den Interessen und bietet so zahlreiche umsetzbare Datenpunkte, die es ermöglichen, individual-spezifische Erlebnisse zu konstruieren.\n\n## Beispiele für datengestützte Erlebnisse\n\nEin datengestütztes Erlebnis kann sich vom Einfachen bis hin zum Hochkomplexen erstrecken, und es kann sowohl im anonymen als auch im bekannten Userbereich konstruiert werden.\n\nEin grundlegendes Beispiel ist die Verfügbarkeit von Filmvorschauen, die regionale Verbote berücksichtigen, basierend auf dem Standort des Benutzers, von welchem aus er die Seite aufruft. Ein anderes grundlegendes Beispiel ist die Auswahl von Filmvorschauen, die berücksichtigt, was der Benutzer bereits gelesen hat, und somit sicherstellt, dass der Benutzer bei jedem Besuch neuen Inhalt vorfindet.\n\nEin eher komplexes Beispiel ist die Auswahl von Artikeln basierend auf einer persönlichen Taxonomy der Interessen und dessen Bewertung durch maschinelles Lernen und in der Nähe zu anderen Benutzern.\n\nEin weiteres komplexes Beispiel ist die Empfehlung eines neuen Autos für einen Benutzer zu der Zeit, zu der er sich gerade zum ersten Mal auf einer Webseite für Autobewertungen befindet, ausgewählt durch die Benutzung von Nachbarschaftsanalyse und erweitert durch maschinelles Lernen, während der Benutzer sich im Prozess befindet. Diese Daten können dann an ein vorliegendes Call Centre weitergegeben werden, um einen informierten und relevanten Concierge Service anzubieten, der den Benutzer bis zur Zustellung des neuen Autos begleitet.\n\n ## Wie funktioniert das?\n\nIm Herzen der DADI Plattform liegt das Konzept der anonymen UUID: Eine dauerhafte anonymisierte Benutzerdatei, die über verschiedene Produkte hinweg verfügbar ist. Dies wird durch DADI Identity ermöglicht. Wird es in Verbindung mit DADI Track benutzt, ermöglicht Identity die Überwachung jeglicher Aktionen, die im Produkt getätigt werden, und diese Daten können an den bekannten Ort übermittelt werden, wenn der Benutzer sich registriert/anmeldet.\n\nDie Anwendung von DADI Match auf den Inhalt ermöglicht es, Inhalt nach unserem bekannten taxonomischen Framework zu kategorisieren (das flächendeckendste Framework zur Zeit verfügbar). Match ist eine Oberfläche zu maschinellem Lernen, das in der Lage ist, die Bedeutung von Aktionen zu erkennen. Wenn es mit Inhalt kombiniert wird und an ein UUID gekoppelt wird, erlaubt es einem, persönliche Taxonomien in Echtzeit zu erstellen und herauszubilden.\n\nAll diese Daten werden dann in einen Front-End Generator für ein Produkt vor der Durchführung der Datenquelle eingespeist, was die Bearbeitung des Inhalts basierend auf allem, was über das Individuum bekannt ist, ermöglicht.\n\nWährend die Plattform lernt, wird sie akurater und bietet ein immer besseres Verständnis des Individuums.\n\nWenn es in Verbidnung mit einer Moment Map - unserer Kommunikations- und Verabredungsstrategie - kombiniert wird, ermöglicht DADI den Aufbau einer bedeutsamen Beziehung, den Aufbau von Loyalität, Erweiterung der Kundenbindung und eine verbesserte Umsetzung."
        },
        {
          "lang": "de",
          "handle": "api-first-and-cope",
          "title": "API-first und COPE",
          "overview": "Das API-first Projekt ist der Gedanke, wann auch immer ein Beitrag entwickelt wird, der geteilte Funktionalität in der Firma hat, sollte es als RESTful HTTP(S) API allen anderen Entwicklern der Firma zur Verfügung stehen.",
          "body": "## Überblick\n\nTraditionelles Produktdesign ist Kanal- und Endgerätezentriert. Aber Benutzer leben in einer Welt mit verschiedenen Kanälen und verschiedenen Endgeräten.\n\nKanal- und/oder Endgerätezentriertes Produktdesign führt zu doppeltem Arbeitsaufwand und verschwendet Arbeitskraft der Entwickler. API-first ist darauf bedacht, diese technische Bürde zu beseitigen, indem die Backend Daten und das datenintensive Frontend separiert werden\n\nAPI-first ist der Gedanke, wann auch immer ein Beitrag entwickelt wird, der geteilte Funktionalität in der Firma hat, sollte es als RESTful HTTP(S) API allen anderen Entwicklern der Firma zur Verfügung stehen.  Anstatt eine Biblothek oder Modul zu erstellen, das zu jeder Codebasis hinzugefügt werden muss, was die Voraussetzung für die Funktionalität ist, können die Entwickler auf alle nötigen Funktionen durch das API zugreifen. Wenn die Entwickler auf alle Funktionen durch das API zugreifen müssen, zwingt das zu einer Trennung der Zuständigkeiten und verschleiert interne Komplexität\n\nCOPE steht für Create Once, Publish Everywhere. Es geht darum, editoriellen Mehraufwand zu verringern, in dem der Inhalt für die Benutzung in mehreren verschiedenen Kontexten freigestellt wird. Einfach ausgedrückt trennt COPE Daten vom Design, was den Inhalt wiederverwendbar und zukunftssicher für neue Endgeräte und Plattformen macht.\n\nNutzt man die API-first Entwicklung, bringt dies COPE einige weitere Vorteile:\n\n1.Trennung der Zuständigkeiten\n2. Skalierbarkeit\n3. Verringerung von Sprachbarrieren\n4. Freiheit für Entwickler und deren Spezialisierung\n5. Offenheit und zukünftige Kundenverfügbarkeit\n6. Modularität\n\n## 1. Trennung der Zuständigkeiten\n\nAPI-first ist die formale Trennung des Frontend vom Backend.\n\nÄhnlich dem Model View Controller Paradigma, wo Daten, Logik und Präsentation entkoppelt werden, zwingt es zu einer besseren Codearchitektur, was auf lange Sicht betrachtet die technischen Hürden verringert. API-first vereinfacht es, Daten zur mehrfachen Betrachtung zu versenden, egal welcher Größe oder Funktionalität.\n\n## 2. Skalierbarkeit\n\nFrontend und Backend Codebasis komplett voneinander zu trennen hilft dabei, zukünftige Skalierbarkeit zu vereinfachen, indem es ermöglicht, Plattformkomponenten unabhängig voneinander zu skalieren. Es erlaubt sowohl dem Client als auch dem Server, hinter ihrem eigenen Load Balancer und in ihrer eigenen Infrastruktur zu sitzen, während sie die Möglichkeit haben, auf der Mikroebene zu skalieren, was Flexibilität ermöglicht (zum Beispiel können Daten zentral gespeichert werden, während der Client in verschiedenen geographischen Standorten gehosted wird) und Kosten einspart.\n\n## 3. Verringerung der Sprachbarrieren\n\nIhr API sollte ihre Geschäftsidee widerspiegeln. Ausgliedern gibt Ihnen die Möglichkeit, auf verschiedene Kanäle zu expandieren und verschiedene Endgeräte zu unterstützen, alles in Benutzung des gleichen Backends.\n\nIhr API agiert als universale Sprache, mit der all ihre Clients interagieren können. Selbst wenn sie expandieren, wird jedes Team dieselbe Sprache sprechen und verstehen. Die Erwartungen sind immer die selben: Der gleiche Erfolg, die gleichen Fehler. Besser noch, wenn jeder JSON kennt und fast jeder auf der Höhe mit REST ist, sodass API weltweit verstanden wird.\n\n## 4. Freiheit für Entwickler und deren Spezialisierung\n\nAPI-first befreit die Entwickler. Die einzige Sache, die Anwendungsentwickler wissen müssen, ist die Frage/Antwort Sequenz jedes API Endpunkts und einige potentielle Fehlercodes. Dasselbe gilt für Handyentwickler, und jede andere Art von Entwickler in diesem Bereich.\n\nDie Wirtschaft entwickelt sich weiter, wenn Wissen eine Black Box wird. Stellen sie sich vor, sie müssten wissen wie ein Mikrochip von Grundauf aufgebaut wird, um eine Internetanwendung zu erstellen. Dank der Spezialisierung und Arbeitsteilung brauchen sie sich nur auf den Code konzentrieren. Das ist der Vorteil von API-first.\n\nDieser Ansatz befreit auch das Frontend Entwicklungsteam, damit es sich auf einige spezielle Verfahren zur Interaktion mit den Daten konzentrieren kann, und das Backend Team kann sich darauf fokussieren, diese in einer RESTful Art und Weise bereitzustellen.\n\n## 5. Offenheit und zukünftige Kundenverfügbarkeit\n\nAPI-first macht die Öffnung ihres API für die Öffentlichkeit einfach. Und als Client ihres eigenen API haben sie die Möglichkeit, sobald sie mehr Funktionalität hinzufügen, ihren Kunden diese ohne zusätzlichen Mehraufwand zur Verfügung zu stellen.\n\n## 6. Modularität\n\nWarum sollten sie sich mit nur einer Datenquelle zufrieden geben? Mit modernen Internetpraktiken können Sie mehrere APIs kombinieren um schnell ein leistungsstarkes Produkt zu entwickeln. Und wenn sich ihre Wünsche ändern, kann sich auch die Plattform ändern, durch einfaches hinzufügen oder löschen eines API."
        },
        {
          "lang": "de",
          "handle": "microservices",
          "title": "Microservices",
          "overview": "Microservices beschreibt eine Methode, komplexe Anwendungen als eine Serie von kleinen, unabhängigen Prozessen aufzubauen, die unter Benutzung sprachunabhängier APIs miteinander kommunizieren.",
          "body": "## Überblick\n\nDer Begriff \"Microservice Architecture\" beschreibt ein bestimmtes Verfahren zum Design von Softwareanwendungen als eine Suite von unabhängigen, einsatzfähigen Services. Obwohl es keine präzise Definition dieses Architekturstils gibt, gibt es doch einige bestimmte Eigenschaften, unter anderem die Organisation um die geschäftliche Leistungsfähigkeit herum, automatische Einsatzfähigket, Intelligenz in den Endpunkten und dezentrale Kontrolle der Sprachen und Daten.\n\nWir sehen Microservices als logischen Partner des API-first Ansatzes, wo komplexe Anwendungen aus kleinen, unabhängigen Prozessen aufgebaut sind, die unter Benutzung von sprachunabhängiger APIs miteinander kommunizieren. Diese Services sind klein, hochgradig entkoppelt und konzentrieren sich darauf, kleine Aufgaben auszuführen.\n\n## Eigenschaften der Microservice Architecture:\n\n* Die Services lassen sich leicht ersetzen\n* Die Services sind nach ihrem Potential organisiert, z.B. User Schnittstellen Frontend, Empfehlung, Logistik, Abrechnung, etc.\n\n## Eine Microservice basierende Architektur:\n\n* Eignet sich für einen kontinuierlichen Softwareentwicklungsprozess\n* Ist abgesetzt von einer serviceorientierten Architektur (SOA) in dem Sinne, dass Letzteres zum Ziel hat, verschiedene (geschäftliche) Anwendungen zu integrieren, während Microservices nur zu einer Anwendung gehören.\n\n## Produkte, keine Projekte\n\nDie meisten Bestreben zur Anwendungsentwicklung, die wir kennen, nutzen ein Projektmodell, mit dem Ziel, dass ein Stück Software ausgeliefert wird, welches dann als abgeschlossen angesehen wird. Nach Abschluss wird die Software an eine Wartungsfirma ausgehändigt und das Projektteam, dass diese entwickelte, wird aufgelöst.\n\nBefürworter von Microservice tendieren dazu, dieses Modell zu vermeiden, und bevorzugen stattdessen lieber die Auffassung, dass das Team das Produkt über die Lebenszeit hinweg besitzen sollte. Eine gängige Inspiration dafür ist Amazons Auffassung von \"Ihr baut es, also betreibt ihr es auch\", bei der das Entwicklerteam die volle Verantwortung für die Software in der Produktion trägt. Dies bringt die Entwickler in täglichen Kontakt damit, wie sich ihre Software in der Produktion verhält und erhöht den Kontakt mit den Benutzern, weil sie zumindest einen Teil der Support Bürde tragen müssen.\n\nDie Produktmentalität ist verbunden mit der Geschäftstauglichkeit. Anstatt die Software nur als ein Satz von Funktionalitäten anzusehen, der abgeschlossen ist, gibt es eine dauerhafte Beziehung mit der Fragestellung, wie die Software den Benutzern helfen kann, ihre Geschäftstauglichkeit zu verbessern.\n\n## Wie groß ist ein Microservice?\n\nObwohl \"Microservice\" einen Architekturstil beschreibt, lässt der Name unglücklicherweise auf die wortwörtliche Größe des Service schließen, und auf Streitigkeiten, was \"micro\" alles beinhaltet.\n\nDie größte uns bekannte Größe folgt Amazons Auffassung der zwei Pizzen (d.h. das gesamte Team kann mit zwei Pizzen ernährt werden), was bedeutet, dass es nicht mehr als ein Dutzend Menschen sind. Auf der anderen Seite des Spektrums kann auch ein einzelner Entwickler leicht für mehrere Services verantwortlich sein."
        },
        {
          "lang": "de",
          "handle": "machine-learning",
          "title": "Maschinelles Lernen",
          "overview": "Maschinelles Lernen ist nicht wirklich eine Maschine. Es ist eher ein mathematisches Model, das in der Lage ist, Verhaltensmuster zu erlernen und daraufhin ähnliche Muster in neuen Daten vorherzusagen.",
          "body": "## Überblick\n\nDADI ist einzigartig im Umgang mit Daten: Die gesamte Plattform ist darauf ausgerichtet, datengestützte Erlebnisse zu ermöglichen.\n\nIm Kern liegen eine Reihe von kognitiven Anwendungen, die vorausschauende Analysen treffen um einzigartige Erfahrungen zielgerichtet auf ein Individuum zu ermöglichen.\n\n## Kognitiver Einblick mit DADI Predict\n\nDADI Predict ist die erste unserer Anwendungen für maschinelles Lernen. Es ist ein API, das zielgruppenbasierte Vorhersagen vereinfacht, in dem es spezielle Techniken zum maschinellen Lernen verwendet.\n\nIm Prinzip werden Ereignisse in DADI Predict gespeichert und eine Vorhersage über zukünftige Ereignisse kommt dabei heraus.\n\n## Ein arbeitsfähiges Beispiel\n\nDADI Predict nutzt die Konzepte von Ereignissen - bekannt für jeden, der ein GA benutzt - um die einfach Sammlung von Datenpunkten zum Abgleich zu ermöglichen.Ein Ereignis kann in 4 Teile gruppiert werden:\n\n* Person\n* Aktion\n* Objekt\n* Bedeutung\nnZum Beispiel: Benutzer A (die Person) fügt einen Porsche 911 (das Objekt) zu seiner Wunschliste hinzu (die Aktion).\n\nPredict nutzt unsere Tools zur Identifikation - im speziellen die Gewährleistung eines Individuums und eine ausgegebene UUID - um die Kennung der Person in dem Ereignis zu befüllen.\n\nDie Aktion und das Objekt basieren auf der Vorhersage, die wir innerhalb des Produkts machen möchten.\n\nZurück zum Beispiel\n\n1. Benutzer A fügt einen Porsche 911 zu seiner Wunschliste hinzu.\n2. Benutzer B fügt einen Porsche 911 und eine Mercedes S-Klasse zu seiner Wunschliste hinzu.\n\nDies erlaubt uns, vorherzusagen, dass Benutzer A wahrscheinlich eher an einer Mercedes S-Klasse interessiert sein wird als an einem zufällig ausgewählten Model.\n\nDer analytische Ansatz, der hier genutzt wird, nennt sich kollaboratives Filtern: Die Vorhersage von Interessen eines Einzelnen (filtern), ermittelt auf Basis der Interessen Vieler (kollaborativ).\n\nDas System arbeitet am besten in größeren Dimensionen. Allgemein gesagt benötigt es mindestens 20 mal mehr Datenpunkte als Variablen.\n\nUnd je mehr Daten es bekommt, desto besser wird es."
        },
        {
          "lang": "jp",
          "handle": "data-driven-experiences",
          "title": "データ駆動型エクスペリエンス",
          "overview": "複数の接点における個人向けにカスタマイズされた体験を提供するべく、リアルタイムのユーザーおよび環境データを処理して理解する能力。",
          "body": "## 概要\n\nDADIはデータへのアプローチがユニークです。プラットフォーム全体が、データ駆動型エクスペリエンスを促進ように構築されています。\n\nデータ駆動型エクスペリエンスとは、プロダクト (Webサイト、アプリ、またはその他のデジタルチャネル) とのやりとりで、個人レベルのデータを裏付けとした決定の結果として個々人にユニークとなるものです。\n\nDADIは、個人というコンセプトをプラットフォームの中心に置いています。リアルタイムに個人レベルの興味分類を作成し、個人向けのエクスペリエンスを創出できるように、複数の実行可能なデータポイントを提供します。\n\n## データ駆動型エクスペリエンスの例\n\nデータ駆動型エクスペリエンスは、単純なものから非常に複雑なものにまで及ぶ可能性があります。匿名および既知の両方のユーザー空間に構築できます。\n1つの基本的な例は、映画レビューの配信です。ページ要求時点でのユーザーの場所に基づいて地域の制限を配慮します。もう1つの基本的な例は、新しい映画のレビューを選択することです。ユーザーが既に読んだレビューを尊重して、訪問のたびに新しいコンテンツを受け取ることを保証するようにします。\n\nより複雑な例は、個人のために記事を選択することです。個人レベルの興味分類に基づき、また機械学習や他のユーザーとの近さを利用して重み付けされます。\n\nもう1つの複雑な例は、車レビューのWebサイトにユーザーが最初に対話したときにユーザーに新しい車を推奨することです。近さのマッピングを使用して選択されます。また、ユーザーが処理に関与するについて機械学習により強化されます。このデータはコールセンターにまで及びます。知識を持って適切なコンシェルジュサービスを可能として、ユーザーを新しい車の受け渡し地点に近づくように導きます。\n\n## どのように動作しますか？\nDADIプラットフォームの中心は、匿名のUUIDというコンセプトです。これは、クロスプロダクトで利用することのできる永続的で匿名のユーザーレコードです。これはDADI Identityによって提供されます。\n\nDADI Trackと連携して使用されることで、Identityはプロダクト内で行われたすべてのアクションの監視を可能とします。また、ユーザーのサインアップやサインインの時点でこのデータを既知のスペースに渡すことができます。\n\nコンテンツにDADI Matchを適用することにより、一般的な分類フレームワーク (利用可能な最も包括的なフレームワーク) に対してコンテンツを自動的に分類することが可能です。Matchは、アクションの意味を理解できる機械学習のレイヤーです。コンテンツにマッチしてUUIDに結び付けられた場合、これにより、個人レベルでの分類をリアルタイムで作成して進化させることができます。\nこのデータはすべて、データソースの実行に先立って、プロダクトのフロントエンドジェネレータにパイプされます。個人に関する分かっていることに基づいてコンテンツを操作することができます。\n\nプラットフォームの学習が進むにつれて、正確さを増し、個人に対するより進んだ理解を提供します。\n\nモーメントマップ (コミュニケーションとエンゲージメントの戦略) と連動させることで、DADIは、有意義な関係の構築、ロイヤルティの構築、エンゲージメントの強化、コンバージョンの向上を可能とします。"
        },
        {
          "lang": "jp",
          "handle": "api-first-and-cope",
          "title": "APIファーストとCOPE",
          "overview": "APIファーストの開発とは、組織に共有の機能を開発するときはいつでも、他のすべての開発者にRESTfulなHTTP(S) APIとして公開する必要があるという考え方です。",
          "body": "## 概要\n\n伝統的なプロダクト設計はチャネルとデバイスが中心です。しかし、ユーザーはマルチチャネル、マルチデバイスの世界に生きています。\n\nチャネルやデバイス中心のプロダクト設計は、重複した労力と無駄なエンジニアリング作業につながります。APIファーストの開発は、データバックエンドとデータ利用のフロントエンドとを分離することによって、この技術的債務をなくすことに着目しています。\n\nAPIファーストの開発は、組織に共有の機能を開発するときはいつでも、他のすべての開発者にRESTfulなHTTP(S) APIとして公開する必要があるという考え方です。機能を必要とするすべてのコードベースに追加する必要のあるライブラリやモジュールを作成するのではなく、開発者はAPIを通じて必要な機能をすべて使用できます。開発者にAPIを介してすべての機能を消費させると、懸念事項の分離を強制することになり、内部の複雑さを隠すことにもなります。\n\nCOPEはCreate Once、Publish Everywhereの略です。複数の異なるコンテキストで使用するためにコンテンツを解放することにより、編集のオーバーヘッドを削減するものです。簡単に言えば、COPEはデザインからデータを分離して、新しいデバイスやプラットフォームのためにコンテンツを再利用可能で将来にも利用できるようにします。\n\nAPIファーストの開発手法を採用することで、COPEが可能になり、さらにいくつかの利点がもたらされます。\n\n懸念の分離\nスケーラビリティ\n言語障壁の低減\n開発者の解放と専門化\nオープン性と将来の利用者の可用性\nモジュール性\n\n## 1.懸念の分離\n\nAPIファーストの開発は、フロントエンドとバックエンドの正式な分離です。\n\nモデル・ビュー・コントローラーのパラダイムと同様に、データをロジックとプレゼンテーションから切り離すことで、より良いコードアーキテクチャーを強制することになります。長期的には技術的な債務を減らします。APIファーストの開発により、サイズや機能に関係なく、複数のビューにデータを簡単にプッシュすることができます。\n\n## 2.スケーラビリティ\n\nフロントエンドとバックエンドのコードベースを完全に分離することで、プラットフォームコンポーネントを互いに独立してスケールさせることができるので、将来のスケーラビリティを簡素化できます。クライアントとサーバーを独自のロードバランサの背後に置き、独自のインフラストラクチャ内に配置することが可能になります。柔軟性 (たとえば、クライアントが複数の地理的な場所にホストされている場合にもデータを集中的に保存することができます) とコストの節約をもたらすマイクロレベルでの拡張が可能になります。\n\n## 3.言語障壁の低減\n\nAPIはビジネスロジックを反映している必要があります。それを分離することで、同じバックエンドを利用しながら、さまざまなチャンネルに拡張したり、さまざまなデバイスをサポートしたりすることができます。\n\nAPIは普遍的な言語として機能し、いずれのクライアントもそれと対話することができます。規模が拡大しても、すべてのチームが同じ言語を話し、理解することになります。期待するものは常に同じでで、同じ成功、同じエラーです。良いことにはJSONは誰もが知っており、ほとんどの人がRESTを知っていますので、APIは世界的に理解されています。\n\n## 4. 開発者の解放と専門化\n\nAPIファーストの開発は開発者を解放します。アプリケーション開発者が知る必要があるのは、各APIのエンドポイントのリクエスト/レスポンスのシーケンスと可能性のあるエラーコードだけです。同じことはモバイルデベロッパーにもいえます。その他のタイプの開発者にとっても同じことです。\n\n知識が「ブラックボックス化」できるとき産業は前進します。Webアプリケーションを構築するために、マイクロチップをゼロから作る方法を知っていなければならないと想像してみてください。専門化と分業のおかげで、あなたが集中する必要があるのはコードです。これはAPIファースト開発の利点です。\n\nこのアプローチにより、データとやりとりするためのいくつかの特定の方法に集中するように、フロントエンドの開発チームを開放します。またバックエンドチームは、RESTfulな方法で提供することに集中できます。\n\n## 5. オープン性と将来の利用者の可用性\n\nAPIファーストは、あなたのAPIを公開用にすることを容易にします。私たちのAPIのクライアントとして、あなたは機能を追加しつつ、追加のオーバーヘッドなしにそれを利用者に提供することができます。\n\n## 6.モジュール性\n\nなぜ1つだけのデータソースに限定するのですか？最新のWebプラクティスでは、複数のAPIを簡単に組み合わせて強力なプロダクトを素早く作成することができます。また、必要に応じてAPIを追加または削除するだけで、プラットフォームも変更できます。"
        },
        {
          "lang": "jp",
          "handle": "microservices",
          "title": "マイクロサービス",
          "overview": "マイクロサービスとは、複雑なアプリケーションを、言語に依存しないAPIを使用して互いに通信する一連の小さく独立したプロセスとして設計する方法をいいます。",
          "body": "## 概要\n\n「マイクロサービス・アーキテクチャ」という用語は、独立して配備可能なサービスのスイートとしてソフトウェア・アプリケーションを設計する特定の方法をいいます。このアーキテクチャー・スタイルの正確な定義はありませんが、ビジネス機能、自動デプロイメント、エンドポイントのインテリジェンス、言語とデータの分散管理など共通の特性があります。\n\nマイクロサービスは、APIファーストの開発アプローチの論理的パートナーであると考えられます。言語に依存しないAPIを使用して互いに通信する小さな独立したプロセスで複雑なアプリケーションが構成されています。これらのサービスは小さく、高度に分離されており、小さなタスクを実行することに焦点を当てています。\n\n## Microservicesアーキテクチャのプロパティ：\n\n* サービスは簡単に交換できます。\n* サービスは、ユーザーインターフェースのフロントエンド、レコメンド、ロジスティクス、課金などの機能を中心に構成されています。\n\n## マイクロサービスベースのアーキテクチャ：\n\n* 継続的な配信ソフトウェア開発プロセスに適しています。\n* サービス指向アーキテクチャ (SOA) とは異なります。後者はさまざまな (ビジネス) アプリケーションを統合することを目的としており、いくつかのマイクロサービスは1つのアプリケーションにのみ属しています。\n\n## プロジェクトではなくプロダクト\n\nよく見る多くのアプリケーション開発の試みは、完了できると見なされたソフトウェアの一部を提供することを目標としたプロジェクトモデルを使用しています。完成後ソフトウェアはメンテナンス組織に渡され、それを構築したプロジェクトチームは解散されます。\n\nマイクロサービスの支持者は、このモデルを避ける傾向にあります。代わりにチームがプロダクトを全ライフタイムにわたって所有しているべきであるという考えを好みます。このための一般的なインスピレーションは、開発チームが本番ソフトウェアの全面的な責任を負うというAmazonの「あなたが構築し、実行する」という概念です。これにより、開発者は、稼働中のソフトウェアがどのように動作しているかについて日常的に接触し、サポート負担の少なくとも一部を負う必要があるため、ユーザーとの接触が増えます。\n\nプロダクトのメンタリティは、ビジネス能力との関連性に結びついています。ソフトウェアを完成させる一連の機能として見るのではなく、どのようにソフトウェアがユーザーにビジネス能力を高めるのを助けることができるのかという継続的な関連性です。\n\n## マイクロサービスはどれくらいの規模ですか？\n\n「マイクロサービス」は構造上のスタイルを表しているのですが、その名前は残念ながら文字通りサービスのサイズに焦点を当て、何が「マイクロ」を構成するかという議論につながっています。\n私たちは最大のサイズはAmazonのTwo Pizza Team (すなわち、チーム全体が2つのピザで満たされる)という見解に従っています。つまり12人を超えないことになります。その一方で、単一の開発者が複数のサービスを容易に担当できます。\n"
        },
        {
          "lang": "jp",
          "handle": "machine-learning",
          "title": "機械学習",
          "overview": "機械学習は実際には機械ではありません。むしろ数学的モデルです。大きなデータセットのパターンを学習し、それから新しいデータの類似パターンを予測できます。",
          "body": "## 概要\n\nDADIはデータへのアプローチがユニークです。プラットフォーム全体は、データ駆動型エクスペリエンスを容易にするために構築されています。\n\nその中心には、個人を対象としたユニークな体験を創出するための予測分析を提供する一連の認知アプリがあります。\n\n## DADI Predictによる認知的洞察\n\nDADI Predictは、私たちの機械学習アプリケーションの第一弾です。これは、特定の機械学習手法を使用して、オーディエンスベースの予測を簡素化するAPIです。\n\n非常に基本的には、イベントがDADI Predictに入り、将来のイベントに関する予測が出てきます。\n\n## 実際の例\n\nDADI Predictはイベントの概念を使用します。これはGAを使用したことのある人には馴染み深いものです。モデル化の対象となるデータポイントのシンプルな収集を可能にします。\n\nイベントとは、4つのタイプのグループです。\n\n* Person\n* Action\n* Object\n* Weighting\n\n例：ユーザーA (人物) がポルシェ911 (オブジェクト) をウィッシュリスト (アクション) に追加したとします。\nPredictは、特に個人と発行されたUUIDの保証を得る私たちのIDツールを使用します。そのイベントにおけるその人のためのIDを追加します。\n\nアクションとオブジェクトは、プロダクト内で作成したいと思っている予測に基づいています。\n例に戻ると：\n\n* ユーザーAはポルシェ911をウィッシュリストに追加しました。\n* ユーザーBはポルシェ911とメルセデスSクラスをウィッシュリストに追加しました\n\nしたがって、ユーザーAは、無作為に選択されたモデルよりも、メルセデスSクラスに関心を持つ可能性が高いと予測することができます。\n\nここで利用されている分析アプローチは協調フィルタリングと呼ばれます。単一ユーザーの関心の予測 (フィルタリング) を、多くのユーザーの関心に基づいて (協調作業) 計算します。\n\nシステムはスケールして動作するのが最適です。一般に、変数よりも少なくとも20倍以上のデータポイントが必要です。\n投げ入れるデータが多くなればなるほど、出るものは良くなります。"
        }
      ]
    }
  }
}
